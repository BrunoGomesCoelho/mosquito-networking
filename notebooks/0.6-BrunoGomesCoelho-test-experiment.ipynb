{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out a full pytorch experiment, with tensorboard, // processing, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "#%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "#%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.data import make_dataset\n",
    "from src.data import read_dataset\n",
    "from src.data import util\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "df = make_dataset.main(reduce_mem_usage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8dec0fb9b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to pytorch types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vector = util.get_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From numpy option does not send to device!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29457, 1, 22050]) torch.Size([24269, 1, 22050])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train, x_test, y_train, y_test = util.transform_torch(data_vector, device=device)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic 1D convolutional network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1D conv in Pytorch](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv1d) \n",
    "\n",
    "In the simplest case, the output value of the layer with input size\n",
    "\n",
    "$$ (N, C_{\\text{in}}, L) $$ and output $$ (N, C_{\\text{out}}, L_{\\text{out}}) $$ can be\n",
    "\n",
    "$$ (N, C_{\\text{in}}, L) $$ and output $$ (N, C_{\\text{out}}, L_{\\text{out}}) $$ can be\n",
    "    precisely described as:\n",
    "\n",
    "$$\n",
    "        \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
    "        \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n",
    "        \\star \\text{input}(N_i, k)\n",
    "$$ \n",
    "\n",
    "where $$ \\star $$  is the valid \"cross-correlation\"  operator,\n",
    "    N is a batch size, C denotes a number of channels,\n",
    "    L is a length of signal sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class BasicMosquitoNet(nn.Module):\n",
    "    \"\"\"A basic 1D conv net.\n",
    "    We use 1D convolution, followed by max pool, 1D convolution, max pool, FC, FC.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, conv1_out=100, kernel_1=6, stride_1=3, \n",
    "                 conv2_out=10, kernel_2=4, stride_2=2):\n",
    "        \"\"\"\n",
    "        conv1: (22050 - 6)/3  + 1 = 7349\n",
    "        max_pool_1 = floor((Lin + −dilation×(kernel_size−1)−1)/stride_2) + 1\n",
    "                   = floor(7349-2 /2) + 1 = 3673 + 1 = 3674\n",
    "        conv2 = (3674 - 4)/2 + 1 = 1836\n",
    "        max_pool_2 = floor(1836-2 /2) + 1 = 918\n",
    "        \n",
    "        \"\"\"\n",
    "        super(BasicMosquitoNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=conv1_out, \n",
    "                               kernel_size=kernel_1, stride=stride_1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=conv1_out, out_channels=conv2_out, \n",
    "                               kernel_size=kernel_2, stride=stride_2)\n",
    "        self.fc1 = nn.Linear(918*conv2_out, 1)  \n",
    "        #self.fc1 = nn.Linear(918*conv2_out, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        #self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. \n",
    "        \"\"\"\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)), 2)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \"\"\"\n",
    "        # We use BCEWithLogitsLoss instead of applying sigmoid here\n",
    "        # It is better computationally\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "net = BasicMosquitoNet()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 100, 7349]             700\n",
      "            Conv1d-2             [-1, 10, 1836]           4,010\n",
      "            Linear-3                    [-1, 1]           9,181\n",
      "================================================================\n",
      "Total params: 13,891\n",
      "Trainable params: 13,891\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 5.75\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 5.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, input_size=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 32,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "max_epochs = 1\n",
    "\n",
    "version = !python3 --version\n",
    "version = version[0].split(\".\")[1]\n",
    "\n",
    "if int(version) < 7 and params[\"num_workers\"]:\n",
    "    print(\"WARNING\\n\"*10)\n",
    "    print(\"Parallel execution only works for python3.7 or above!\")\n",
    "    print(\"Running in parallel with other versions is not guaranted to work\")\n",
    "    print(\"See https://discuss.pytorch.org/t/valueerror-signal-number-32-out-of-range-when-loading-data-with-num-worker-0/39615/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run in our terminal: \n",
    "\n",
    "`cd notebooks`\n",
    "\n",
    "`tensorboard --logdir runs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "    \n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data generator from dataset for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "training_set = read_dataset.MosquitoDataset(x_train, y_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "testing_set = read_dataset.MosquitoDataset(x_test, y_test)\n",
    "testing_generator = torch.utils.data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple train function\n",
    "def train(net, optimizer):\n",
    "    # Loop over epochs\n",
    "    last_test_loss = 0\n",
    "    for epoch in range(max_epochs):\n",
    "        # Training\n",
    "        for idx, (local_batch, local_labels) in enumerate(training_generator):\n",
    "            optimizer.zero_grad()   # zero the gradient buffers\n",
    "            output = net(local_batch)\n",
    "            loss = criterion(output, local_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()    # Does the update\n",
    "            writer.add_scalar(\"Train Loss Batch\", loss.data.item(), idx)\n",
    "\n",
    "        # Validation\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Transfer to GPU\n",
    "            #local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "            cumulative_test_loss = 0\n",
    "            for idx, (local_batch, local_labels) in enumerate(training_generator):\n",
    "                output = net(local_batch)\n",
    "                loss = criterion(output, local_labels)\n",
    "                writer.add_scalar(\"Test Loss Batch\", loss.data.item(), idx)\n",
    "                \n",
    "                cumulative_test_loss += loss.data.item()\n",
    "            cumulative_test_loss /= idx\n",
    "            last_test_loss = cumulative_test_loss\n",
    "            writer.add_scalar(\"Test Loss Epoch\", loss.data.item(), idx)\n",
    "    \n",
    "    return last_test_loss\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-b4128908af53>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Loss Batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mosquito-networking/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mosquito-networking/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(net, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first Net had a random loss from the second batch onwards with regards to the training - Let's try something really small first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- - - \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new writer\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 7349]             224\n",
      "            Conv1d-2              [-1, 4, 1836]             516\n",
      "            Linear-3                    [-1, 1]           3,673\n",
      "================================================================\n",
      "Total params: 4,413\n",
      "Trainable params: 4,413\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 1.85\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 1.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# create your optimizer\n",
    "net = BasicMosquitoNet(conv1_out=32, conv2_out=4)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "summary(net, input_size=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 44s, sys: 5.55 s, total: 5min 49s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6939035716912021"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train(net, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), \"../models/0.6-BrunoGomesCoelho-test-experiment.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosquito-networking",
   "language": "python",
   "name": "mosquito-networking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
